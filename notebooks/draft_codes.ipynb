{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import scrapy\n",
    "import time\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://staff.am\"\n",
    "main_url = base_url + \"/en/jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to relative paths to job postings from a given page response\n",
    "def get_relative_paths_from_one_page(page_response):\n",
    "    \n",
    "    relative_paths = page_response.css(\"div.web_item_card.hs_job_list_item a.load-more::attr(href)\").getall()\n",
    "    \n",
    "    return relative_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get relative paths for all pages\n",
    "def get_relative_paths_for_all_pages(first_page_response, base_url, delay=3):\n",
    "    \n",
    "    response = first_page_response\n",
    "    relative_paths_for_all_pages = []\n",
    "    \n",
    "    while response.css(\"li.next a\").get() is not None:\n",
    "        \n",
    "        relative_paths_for_all_pages.extend(get_relative_paths_from_one_page(response))\n",
    "        rs = requests.get(base_url + response.css(\"li.next a::attr(href)\").get())\n",
    "        response = scrapy.http.HtmlResponse(url=rs.url, body=rs.text, encoding=\"utf-8\")\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    # Adding relative paths of last page\n",
    "    relative_paths_for_all_pages.extend(get_relative_paths_from_one_page(response))\n",
    "        \n",
    "    return relative_paths_for_all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect data from one job posting\n",
    "def get_info_from_one_posting(absolute_path):\n",
    "    \n",
    "    rs = requests.get(absolute_path)\n",
    "    response = scrapy.http.HtmlResponse(url=rs.url, body=rs.text, encoding=\"utf-8\")\n",
    "\n",
    "    all_default_keys = (\n",
    "        \"Company_Title\", \"Total_views\", \"Followers\", \"Active_Jobs\",\n",
    "        \"Jobs_History\", \"Job_Views\", \"Job_Title\", \"Application_Deadline\",\n",
    "        \"Industry\", \"Employment_term\", \"Job_Category\", \"Job_type\",\n",
    "        \"Job_Location\", \"Job_description\", \"Job_responsibilities\", \"Required_qualifications\", \n",
    "        \"Required_candidate_level\", \"Salary\", \"Additional_information\", \"Professional_skills\",\n",
    "        \"Soft_skills\"\n",
    "    )\n",
    "    \n",
    "    extracted_data = {\n",
    "        \"Company_Title\": response.css(\"h1.job_company_title::text\").get(),\n",
    "        \"Total_views\": response.css(\"div.col-lg-7.company_info_container p.company-page-views span::text\").getall()[0],\n",
    "        \"Followers\": response.css(\"div.col-lg-7.company_info_container p.company-page-views span::text\").getall()[1],\n",
    "        \"Active_Jobs\": response.css(\"p.company-active-job span::text\").get(),\n",
    "        \"Jobs_History\": response.css(\"p.company-job-history span::text\").get(),\n",
    "        \"Job_Views\": re.search(\"[0-9]+\", response.css(\"div.statistics p::text\").get()).group(),\n",
    "        \"Job_Title\": response.css(\"div.col-lg-8 h2::text\").get(),\n",
    "        \"Application_Deadline\": re.search(r\"Deadline: (.*)\\s\", response.css(\"div.col-lg-4.apply-btn-top p::text\").get().replace(\"\\n\", \" \")).group(1)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        extracted_data[\"Industry\"] = response.css(\"div.col-lg-7.company_info_container p.professional-skills-description span::text\").getall()[-1]\n",
    "    except IndexError:\n",
    "        extracted_data[\"Industry\"] = \"None\"\n",
    "\n",
    "    job_info = [i.strip() for i in response.css(\"div.col-lg-6.job-info p::text\").getall() if i != \"\\n\"]\n",
    "    \n",
    "    extracted_data[\"Employment_term\"] = job_info[0]\n",
    "    extracted_data[\"Job_Category\"] = job_info[1]\n",
    "    extracted_data[\"Job_type\"] = job_info[2]\n",
    "    extracted_data[\"Job_Location\"] = job_info[3]\n",
    "    \n",
    "    default_job_list_keys = [\n",
    "        \"Job_description\", \"Job_responsibilities\", \"Required_qualifications\", \n",
    "        \"Required_candidate_level\", \"Salary\", \"Additional_information\"\n",
    "    ]\n",
    "    job_list = response.css(\"div.job-list-content-desc.hs_line_break\")\n",
    "    job_list_keys = [i.strip().replace(\":\", \"\").replace(\" \", \"_\") for i in job_list.css(\"h3::text\").getall()]\n",
    "    \n",
    "    if len(default_job_list_keys) < len(job_list_keys):\n",
    "        print(\"New 'h3' fields in job description list are present: \\nCheck the output.\")\n",
    "    else:\n",
    "        for key in default_job_list_keys:\n",
    "            if key not in job_list_keys:\n",
    "                extracted_data[key] = \"None\"\n",
    "                \n",
    "    for cnt, h3 in enumerate(job_list.css('h3'), start=1):\n",
    "        \n",
    "        key = h3.css(\"::text\").get().strip().replace(\":\", \"\").replace(\" \", \"_\")\n",
    "        \n",
    "        if key in [\"Required_candidate_level\", \"Salary\"]:\n",
    "            extracted_data[key] = h3.css(\"span::text\").get()\n",
    "        else:\n",
    "            values = h3.xpath(\"following-sibling::*[count(preceding-sibling::h3)=$cnt]\", cnt=cnt)[:-1].css(\"::text\").getall()\n",
    "            extracted_data[key] = [value.strip() for value in values if value != \"\\n\"]\n",
    "            \n",
    "    skills_info_keys = [i.replace(\" \", \"_\") for i in response.css(\"div.soft-skills-list.clearfix h3::text\").getall()]\n",
    "    \n",
    "    if \"Professional_skills\" in skills_info_keys:\n",
    "        ind = skills_info_keys.index(\"Professional_skills\")\n",
    "        extracted_data[\"Professional_skills\"] = response.css(\"div.soft-skills-list.clearfix\")[ind].css(\"p span::text, .p::text\").getall()\n",
    "    else:\n",
    "        extracted_data[\"Professional_skills\"] = \"None\"\n",
    "    if \"Soft_skills\" in skills_info_keys:\n",
    "        ind = skills_info_keys.index(\"Soft_skills\")\n",
    "        extracted_data[\"Soft_skills\"] = response.css(\"div.soft-skills-list.clearfix\")[ind].css(\"p span::text, .p::text\").getall()\n",
    "    else:\n",
    "        extracted_data[\"Soft_skills\"] = \"None\"\n",
    "\n",
    "    for key in all_default_keys:\n",
    "        if key not in extracted_data.keys():\n",
    "            print(\"Default field: '{}' is missing in extracted data.\".format(key))\n",
    "            extracted_data[key] = \"None\"\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect data from all job postings given absolute paths\n",
    "def crawl_all_postings(absolute_paths, delay=10):\n",
    "    \n",
    "    extracted_data = {}\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    for path in absolute_paths:\n",
    "\n",
    "        print(path)\n",
    "        print(str(i) + \"/\" + str(len(absolute_paths)), \"Est.: \" + str(round((10 * (len(absolute_paths) - i))/60, 2)) + \"m.\")\n",
    "        i += 1\n",
    "        extracted_data_from_posting = get_info_from_one_posting(path)\n",
    "        \n",
    "        for key, value in extracted_data_from_posting.items():\n",
    "            \n",
    "            if key not in extracted_data.keys():\n",
    "                \n",
    "                extracted_data[key] = []\n",
    "                \n",
    "            extracted_data[key].append(extracted_data_from_posting[key])\n",
    "        \n",
    "        time.sleep(delay)\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect data about companies\n",
    "def crawl_all_companies(absolute_paths_companies):\n",
    "    \n",
    "    # TODO\n",
    "\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make dict data to be saved as csv\n",
    "def format_to_csv(file):\n",
    "    \n",
    "    keys_to_format = (\n",
    "        \"Job_description\", \"Job_responsibilities\", \"Required_qualifications\", \n",
    "        \"Additional_information\", \"Professional_skills\", \"Soft_skills\"\n",
    "    )\n",
    "    \n",
    "    for key, value in file.items():\n",
    "        if key in keys_to_format:\n",
    "            file[key] = \"\\n\".join(file[key])\n",
    "            \n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the data in a given file format\n",
    "def save_files(file, *formats):\n",
    "    \n",
    "    date = datetime.date.today().strftime(\"%d.%m.%y\")\n",
    "    \n",
    "    for ext in formats:\n",
    "        \n",
    "        if ext not in (\"csv\", \"json\"):\n",
    "            print(\"Can't save in {} format.\\nSaving both to 'csv' and 'json'.\".format(ext))\n",
    "            save_files(file, \"csv\", \"json\")\n",
    "            break\n",
    "        elif ext == \"csv\":\n",
    "            file_csv = format_to_csv(file)\n",
    "            try:\n",
    "                file_csv = pd.DataFrame(file_csv)\n",
    "                file_csv.to_csv(\"staff_\" + date + \".csv\")\n",
    "            except ValueError:\n",
    "                print(\"Unable to save 'csv': missing values are present.\\nSaving to 'json'\")\n",
    "                save_files(file, \"json\")\n",
    "                break\n",
    "        elif ext == \"json\":\n",
    "            with open(\"staff_\" + date + \".json\", \"w\") as f:\n",
    "                f.write(json.dumps(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    \n",
    "    start_time = time.ctime()\n",
    "    print(start_time)\n",
    "    print(\"Starting crawling '{}'.\".format(base_url))\n",
    "\n",
    "    rs = requests.get(main_url)\n",
    "    response = scrapy.http.HtmlResponse(url=rs.url, body=rs.text, encoding=\"utf-8\")\n",
    "\n",
    "    relative_paths_for_all_pages = get_relative_paths_for_all_pages(response, base_url, delay=5)\n",
    "    absolute_paths = [base_url + path for path in relative_paths_for_all_pages]\n",
    "\n",
    "    print(str(len(absolute_paths)) + \" jobs detected.\")\n",
    "    print(\"Starting crawling job postings..\")\n",
    "    \n",
    "    extracted_data = crawl_all_postings(absolute_paths)\n",
    "\n",
    "    end_time = time.ctime()\n",
    "    print(end_time)\n",
    "    print(\"Ended crawling '{}'.\".format(base_url))\n",
    "\n",
    "    print(str(len(extracted_data[\"Company_Title\"])) + \"/\" + len(absolute_paths) + \" jobs scraped.\")\n",
    "    print(\"Saving files.\")\n",
    "\n",
    "    for key in data.keys():\n",
    "        print(key + \": \" + str(len(data[key])))\n",
    "\n",
    "    save_files(extracted_data, \"csv\", \"json\")\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  2 07:44:47 2020\n",
      "Starting crawling 'https://staff.am'.\n",
      "796 jobs detected.\n",
      "Starting crawling job postings..\n",
      "https://staff.am/en/brand-manager-60\n",
      "1/796 Est.: 132.5m.\n",
      "https://staff.am/en/1c-operator-14\n",
      "2/796 Est.: 132.33m.\n",
      "https://staff.am/en/sales-consultant-252\n",
      "3/796 Est.: 132.17m.\n",
      "https://staff.am/en/user-success-support-specialist-6\n",
      "4/796 Est.: 132.0m.\n",
      "https://staff.am/en/senior-ios-developer-63\n",
      "5/796 Est.: 131.83m.\n",
      "https://staff.am/en/java-engineer-33\n",
      "6/796 Est.: 131.67m.\n",
      "https://staff.am/en/it-monitoring-specialist-247-shift-9\n",
      "7/796 Est.: 131.5m.\n",
      "https://staff.am/en/senior-c-developer-91\n",
      "8/796 Est.: 131.33m.\n",
      "https://staff.am/en/mobile-software-engineer-in-test-15\n",
      "9/796 Est.: 131.17m.\n",
      "https://staff.am/en/release-engineer-mobile-18\n",
      "10/796 Est.: 131.0m.\n",
      "https://staff.am/en/dizayner-22\n",
      "11/796 Est.: 130.83m.\n",
      "https://staff.am/en/loan-analyst-8\n",
      "12/796 Est.: 130.67m.\n",
      "https://staff.am/en/horeca-manager-3\n",
      "13/796 Est.: 130.5m.\n",
      "https://staff.am/en/data-analyst-41\n",
      "14/796 Est.: 130.33m.\n",
      "https://staff.am/en/restaurant-and-bar-manager\n",
      "15/796 Est.: 130.17m.\n",
      "https://staff.am/en/network-and-operation-system-administrator-1\n",
      "16/796 Est.: 130.0m.\n",
      "New 'h3' fields in job description list are present: \n",
      "Check the output.\n",
      "Default field: 'Salary' is missing in extracted data.\n",
      "https://staff.am/en/senior-reactjs-developer-55\n",
      "17/796 Est.: 129.83m.\n",
      "https://staff.am/en/strong-middle-or-senior-php-developer\n",
      "18/796 Est.: 129.67m.\n",
      "https://staff.am/en/mid-level-software-engineer\n",
      "19/796 Est.: 129.5m.\n",
      "https://staff.am/en/backend-engineer-1\n",
      "20/796 Est.: 129.33m.\n",
      "https://staff.am/en/hh-aragacotni-marzi-arevuti-himnakan-dproc-poak-i-tnoreni-paston-zbagecnelu-hamar\n",
      "21/796 Est.: 129.17m.\n",
      "https://staff.am/en/seo-specialist-52\n",
      "22/796 Est.: 129.0m.\n",
      "https://staff.am/en/varkayin-masnaget-gyumri-masnacyugum-1\n",
      "23/796 Est.: 128.83m.\n",
      "https://staff.am/en/javascript-programmer-1\n",
      "24/796 Est.: 128.67m.\n",
      "https://staff.am/en/ip-engineer-1\n",
      "25/796 Est.: 128.5m.\n",
      "https://staff.am/en/incident-management-specialist-16\n",
      "26/796 Est.: 128.33m.\n",
      "https://staff.am/en/business-development-officer-1\n",
      "27/796 Est.: 128.17m.\n",
      "https://staff.am/en/customer-service-specialistnoyemberyan-1\n",
      "28/796 Est.: 128.0m.\n",
      "https://staff.am/en/customer-service-specialistartashat-1\n",
      "29/796 Est.: 127.83m.\n",
      "https://staff.am/en/customer-service-specialistyeghvard-6\n",
      "30/796 Est.: 127.67m.\n",
      "https://staff.am/en/archivist-6\n",
      "31/796 Est.: 127.5m.\n",
      "https://staff.am/en/payment-analyst\n",
      "32/796 Est.: 127.33m.\n",
      "https://staff.am/en/firmayin-xanuti-vacaroguhi-stepanakertum-2\n",
      "33/796 Est.: 127.17m.\n",
      "https://staff.am/en/participant-in-leadership-development-program\n",
      "34/796 Est.: 127.0m.\n",
      "https://staff.am/en/sukayi-zargacman-patasxanatu-21\n",
      "35/796 Est.: 126.83m.\n",
      "https://staff.am/en/lo-of-armavir-branch-2\n",
      "36/796 Est.: 126.67m.\n",
      "https://staff.am/en/head-of-marketing-department-19\n",
      "37/796 Est.: 126.5m.\n",
      "https://staff.am/en/varkayin-masnaget-stepanavani-masnacyugum\n",
      "38/796 Est.: 126.33m.\n",
      "https://staff.am/en/specialist-in-customer-service-department-6\n",
      "39/796 Est.: 126.17m.\n",
      "https://staff.am/en/sparogakan-varkavorman-masnaget-vayoc-jori-masnacyugum-1\n",
      "40/796 Est.: 126.0m.\n",
      "https://staff.am/en/sparogakan-varkavorman-masnaget-talini-masnacyugum-1\n",
      "41/796 Est.: 125.83m.\n",
      "https://staff.am/en/accountant-354\n",
      "42/796 Est.: 125.67m.\n",
      "https://staff.am/en/smm-specialist-204\n",
      "43/796 Est.: 125.5m.\n",
      "https://staff.am/en/technical-accountant\n",
      "44/796 Est.: 125.33m.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
